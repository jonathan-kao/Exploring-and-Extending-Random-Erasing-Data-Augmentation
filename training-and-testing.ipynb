{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-20T11:10:02.335748Z","iopub.status.busy":"2023-11-20T11:10:02.335439Z","iopub.status.idle":"2023-11-20T11:10:09.235605Z","shell.execute_reply":"2023-11-20T11:10:09.234281Z","shell.execute_reply.started":"2023-11-20T11:10:02.335702Z"},"trusted":true},"outputs":[],"source":["import os\n","import time\n","import sys\n","\n","# If you are not using Kaggle Notebook, please import the necessary files in the proper way\n","sys.path.append('/kaggle/input/resnetgray/')\n","sys.path.append('/kaggle/input/newretransform/')\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim\n","import torch.utils.data\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","\n","# This line imports the existing ResNets architectures, train functions, and custom 1-channel ResNets\n","import resnetgray\n","\n","# This line imports the extended RE transformation function\n","from new_retransform import RandomErasingTransform\n","\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","        \n","if not os.path.exists('/kaggle/working/save_temp'):\n","    os.mkdir('/kaggle/working/save_temp')\n","    \n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T11:14:47.485493Z","iopub.status.busy":"2023-11-20T11:14:47.484884Z","iopub.status.idle":"2023-11-20T11:14:47.491146Z","shell.execute_reply":"2023-11-20T11:14:47.490162Z","shell.execute_reply.started":"2023-11-20T11:14:47.485458Z"},"trusted":true},"outputs":[],"source":["# Idelbayev, Y. Proper ResNet implementation for CIFAR10/CIFAR100 in PyTorch. https://github.com/akamaster/pytorch_resnet_cifar10\n","# Slightly modify to get information from the extended 1-channel Resnet architectures module\n","\n","model_names = sorted(name for name in resnetgray.__dict__\n","    if name.islower() and not name.startswith(\"__\")\n","                     and name.startswith(\"resnet\")\n","                     and callable(resnetgray.__dict__[name]))\n","\n","print(model_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T11:14:54.430128Z","iopub.status.busy":"2023-11-20T11:14:54.429702Z","iopub.status.idle":"2023-11-20T11:14:54.434765Z","shell.execute_reply":"2023-11-20T11:14:54.433795Z","shell.execute_reply.started":"2023-11-20T11:14:54.430098Z"},"trusted":true},"outputs":[],"source":["# Idelbayev, Y. Proper ResNet implementation for CIFAR10/CIFAR100 in PyTorch. https://github.com/akamaster/pytorch_resnet_cifar10\n","\n","best_prec1 = 0\n","\n","class Args:\n","    pass\n","\n","args = Args()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T11:14:56.881451Z","iopub.status.busy":"2023-11-20T11:14:56.881078Z","iopub.status.idle":"2023-11-20T11:14:56.893292Z","shell.execute_reply":"2023-11-20T11:14:56.892266Z","shell.execute_reply.started":"2023-11-20T11:14:56.881404Z"},"trusted":true},"outputs":[],"source":["# Idelbayev, Y. Proper ResNet implementation for CIFAR10/CIFAR100 in PyTorch. https://github.com/akamaster/pytorch_resnet_cifar10\n","\n","\n","def train(train_loader, model, criterion, optimizer, epoch):\n","\n","    global args\n","\n","    \"\"\"\n","        Run one train epoch\n","    \"\"\"\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    top1 = AverageMeter()\n","\n","    # switch to train mode\n","    model.train()\n","\n","    end = time.time()\n","    for i, (input, target) in enumerate(train_loader):\n","\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","\n","        target = target.cuda()\n","        input_var = input.cuda()\n","        target_var = target\n","        if args.half:\n","            input_var = input_var.half()\n","\n","        # compute output\n","        output = model(input_var)\n","        loss = criterion(output, target_var)\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        output = output.float()\n","        loss = loss.float()\n","        # measure accuracy and record loss\n","        prec1 = accuracy(output.data, target)[0]\n","        losses.update(loss.item(), input.size(0))\n","        top1.update(prec1.item(), input.size(0))\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % args.print_freq == 0:\n","            print('Epoch: [{0}][{1}/{2}]\\t'\n","                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n","                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n","                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n","                      epoch, i, len(train_loader), batch_time=batch_time,\n","                      data_time=data_time, loss=losses, top1=top1))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T11:14:59.840832Z","iopub.status.busy":"2023-11-20T11:14:59.840430Z","iopub.status.idle":"2023-11-20T11:14:59.852024Z","shell.execute_reply":"2023-11-20T11:14:59.850778Z","shell.execute_reply.started":"2023-11-20T11:14:59.840799Z"},"trusted":true},"outputs":[],"source":["# Idelbayev, Y. Proper ResNet implementation for CIFAR10/CIFAR100 in PyTorch. https://github.com/akamaster/pytorch_resnet_cifar10\n","\n","def validate(val_loader, model, criterion):\n","\n","    global args\n","\n","    \"\"\"\n","    Run evaluation\n","    \"\"\"\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    top1 = AverageMeter()\n","\n","    # switch to evaluate mode\n","    model.eval()\n","\n","    end = time.time()\n","    with torch.no_grad():\n","        for i, (input, target) in enumerate(val_loader):\n","            target = target.cuda()\n","            input_var = input.cuda()\n","            target_var = target.cuda()\n","\n","            if args.half:\n","                input_var = input_var.half()\n","\n","            # compute output\n","            output = model(input_var)\n","            loss = criterion(output, target_var)\n","\n","            output = output.float()\n","            loss = loss.float()\n","\n","            # measure accuracy and record loss\n","            prec1 = accuracy(output.data, target)[0]\n","            losses.update(loss.item(), input.size(0))\n","            top1.update(prec1.item(), input.size(0))\n","\n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","            if i % args.print_freq == 0:\n","                print('Test: [{0}/{1}]\\t'\n","                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n","                      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n","                          i, len(val_loader), batch_time=batch_time, loss=losses,\n","                          top1=top1))\n","\n","    print(' * Prec@1 {top1.avg:.3f}'\n","          .format(top1=top1))\n","\n","    return top1.avg"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T11:15:02.723850Z","iopub.status.busy":"2023-11-20T11:15:02.723460Z","iopub.status.idle":"2023-11-20T11:15:02.729424Z","shell.execute_reply":"2023-11-20T11:15:02.728036Z","shell.execute_reply.started":"2023-11-20T11:15:02.723818Z"},"trusted":true},"outputs":[],"source":["# Idelbayev, Y. Proper ResNet implementation for CIFAR10/CIFAR100 in PyTorch. https://github.com/akamaster/pytorch_resnet_cifar10\n","\n","def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n","    \"\"\"\n","    Save the training model\n","    \"\"\"\n","    torch.save(state, filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T11:15:04.745659Z","iopub.status.busy":"2023-11-20T11:15:04.744891Z","iopub.status.idle":"2023-11-20T11:15:04.752284Z","shell.execute_reply":"2023-11-20T11:15:04.751291Z","shell.execute_reply.started":"2023-11-20T11:15:04.745624Z"},"trusted":true},"outputs":[],"source":["# Idelbayev, Y. Proper ResNet implementation for CIFAR10/CIFAR100 in PyTorch. https://github.com/akamaster/pytorch_resnet_cifar10\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T11:15:06.881782Z","iopub.status.busy":"2023-11-20T11:15:06.881387Z","iopub.status.idle":"2023-11-20T11:15:06.889140Z","shell.execute_reply":"2023-11-20T11:15:06.888208Z","shell.execute_reply.started":"2023-11-20T11:15:06.881743Z"},"trusted":true},"outputs":[],"source":["# Idelbayev, Y. Proper ResNet implementation for CIFAR10/CIFAR100 in PyTorch. https://github.com/akamaster/pytorch_resnet_cifar10\n","\n","def accuracy(output, target, topk=(1,)):\n","    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n","    maxk = max(topk)\n","    batch_size = target.size(0)\n","\n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","    res = []\n","    for k in topk:\n","        correct_k = correct[:k].view(-1).float().sum(0)\n","        res.append(correct_k.mul_(100.0 / batch_size))\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T11:15:09.209865Z","iopub.status.busy":"2023-11-20T11:15:09.209453Z","iopub.status.idle":"2023-11-20T11:15:09.235335Z","shell.execute_reply":"2023-11-20T11:15:09.234045Z","shell.execute_reply.started":"2023-11-20T11:15:09.209831Z"},"trusted":true},"outputs":[],"source":["# Idelbayev, Y. Proper ResNet implementation for CIFAR10/CIFAR100 in PyTorch. https://github.com/akamaster/pytorch_resnet_cifar10\n","# Slightly modify to train on the Fasion-MNIST dataset\n","# Please modify the transforms of the dataloader to train models with different data augmentations\n","\n","def main_advanced_re_mnist(arch='resnet20gray', workers=4, epochs=200, start_epoch=0, batch_size=128, lr=0.1,\n","         momentum=0.9, weight_decay=1e-4, print_freq=50, resume='', evaluate=False,\n","         pretrained=False, half=False, save_dir='./save_temp', save_every=10):\n","\n","    global best_prec1\n","    global args\n","\n","\n","    args.arch = arch\n","    args.workers = workers\n","    args.epochs = epochs\n","    args.start_epoch = start_epoch\n","    args.batch_size = batch_size\n","    args.lr = lr\n","    args.momentum = momentum\n","    args.weight_decay = weight_decay\n","    args.print_freq = print_freq\n","    args.resume = resume\n","    args.evaluate = evaluate\n","    args.pretrained = pretrained\n","    args.half = half\n","    args.save_dir = save_dir\n","    args.save_every = save_every\n","\n","    model = torch.nn.DataParallel(resnetgray.__dict__[args.arch]())\n","    model.cuda()\n","\n","    # optionally resume from a checkpoint\n","    if args.resume:\n","        if os.path.isfile(args.resume):\n","            print(\"=> loading checkpoint '{}'\".format(args.resume))\n","            checkpoint = torch.load(args.resume)\n","            args.start_epoch = checkpoint['epoch']\n","            best_prec1 = checkpoint['best_prec1']\n","            model.load_state_dict(checkpoint['state_dict'])\n","            print(\"=> loaded checkpoint '{}' (epoch {})\"\n","                  .format(args.evaluate, checkpoint['epoch']))\n","        else:\n","            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n","\n","    cudnn.benchmark = True\n","\n","    normalize = transforms.Normalize(mean=[0.5], std=[0.5])\n","\n","    train_loader = torch.utils.data.DataLoader(\n","        datasets.FashionMNIST(root='./data', train=True, transform=transforms.Compose([\n","            transforms.RandomHorizontalFlip(),\n","            transforms.RandomCrop(28, 4),\n","            transforms.ToTensor(),\n","\n","#             Comment out all the following RE transforms to train Baseline model\n","\n","#             Training RE model:            \n","#             transforms.RandomErasing(),\n","\n","#             Training RE cs:\n","#             RandomErasingTransform(probability=0.5, value=0, sl=0.02, sh=0.33, shape=\"circle\", blend_edges=False, blend_type=\"random\", blend_factor=0),\n","\n","#             Training RE rs:\n","#             RandomErasingTransform(probability=0.5, value=0, sl=0.02, sh=0.33, shape=\"random\", blend_edges=False, blend_type=\"random\", blend_factor=0),\n","\n","#             Training RE be:\n","#             RandomErasingTransform(probability=0.5, value=0, sl=0.02, sh=0.33, shape=\"rectangle\", blend_edges=True, blend_type=\"random\", blend_factor=0),\n","\n","#             Training RE cs-be:\n","#             RandomErasingTransform(probability=0.5, value=0, sl=0.02, sh=0.33, shape=\"circle\", blend_edges=True, blend_type=\"random\", blend_factor=0),\n","\n","#             Training RE rs-be:\n","#             RandomErasingTransform(probability=0.5, value=0, sl=0.02, sh=0.33, shape=\"random\", blend_edges=True, blend_type=\"random\", blend_factor=0),\n","            \n","            normalize,\n","        ]), download=True),\n","        batch_size=args.batch_size, shuffle=True,\n","        num_workers=args.workers, pin_memory=True)\n","\n","    val_loader = torch.utils.data.DataLoader(\n","        datasets.FashionMNIST(root='./data', train=False, transform=transforms.Compose([\n","            transforms.ToTensor(),\n","            normalize,\n","        ])),\n","        batch_size=128, shuffle=False,\n","        num_workers=args.workers, pin_memory=True)\n","\n","    # define loss function (criterion) and optimizer\n","    criterion = nn.CrossEntropyLoss().cuda()\n","\n","    if args.half:\n","        model.half()\n","        criterion.half()\n","\n","    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n","                                momentum=args.momentum,\n","                                weight_decay=args.weight_decay)\n","\n","    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n","                                                        milestones=[int(epochs*0.5), int(epochs*0.75)], last_epoch=args.start_epoch - 1, gamma=0.1)\n","\n","    if args.arch in ['resnet1202', 'resnet110']:\n","        # for resnet1202 original paper uses lr=0.01 for first 400 minibatches for warm-up\n","        # then switch back. In this setup it will correspond for first epoch.\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = args.lr*0.1\n","\n","\n","    if args.evaluate:\n","        validate(val_loader, model, criterion)\n","        return\n","\n","    for epoch in range(args.start_epoch, args.epochs):\n","\n","        # train for one epoch\n","        print('current lr {:.5e}'.format(optimizer.param_groups[0]['lr']))\n","        train(train_loader, model, criterion, optimizer, epoch)\n","        lr_scheduler.step()\n","\n","        # evaluate on validation set\n","        prec1 = validate(val_loader, model, criterion)\n","\n","        # remember best prec@1 and save checkpoint\n","        is_best = prec1 > best_prec1\n","        best_prec1 = max(prec1, best_prec1)\n","\n","        if epoch > 0 and epoch % args.save_every == 0:\n","            save_checkpoint({\n","                'epoch': epoch + 1,\n","                'state_dict': model.state_dict(),\n","                'best_prec1': best_prec1,                 \n","                # Change the output model name corresponding to the augmentation to be more organized in managing models\n","            }, is_best, filename=os.path.join(args.save_dir, 'checkpoint_baseline.th')) \n","\n","        save_checkpoint({\n","            'state_dict': model.state_dict(),\n","            'best_prec1': best_prec1,\n","            # Change the output model name corresponding to the augmentation to be more organized in managing models\n","        }, is_best, filename=os.path.join(args.save_dir, 'model_re_mnist_baseline.th'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T11:15:13.275542Z","iopub.status.busy":"2023-11-20T11:15:13.274773Z","iopub.status.idle":"2023-11-20T11:15:42.816381Z","shell.execute_reply":"2023-11-20T11:15:42.814614Z","shell.execute_reply.started":"2023-11-20T11:15:13.275503Z"},"trusted":true},"outputs":[],"source":["# Start training\n","main_advanced_re_mnist(arch='resnet20gray', workers=2, epochs=300, print_freq=468)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T11:15:48.383396Z","iopub.status.busy":"2023-11-20T11:15:48.383027Z","iopub.status.idle":"2023-11-20T11:15:48.397969Z","shell.execute_reply":"2023-11-20T11:15:48.397064Z","shell.execute_reply.started":"2023-11-20T11:15:48.383366Z"},"trusted":true},"outputs":[],"source":["# Baseline Fashion-MNIST Testloader\n","\n","normalize = transforms.Normalize(mean=[0.5], std=[0.5])\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    normalize\n","])\n","\n","testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T11:15:51.121798Z","iopub.status.busy":"2023-11-20T11:15:51.121432Z","iopub.status.idle":"2023-11-20T11:15:51.177277Z","shell.execute_reply":"2023-11-20T11:15:51.176214Z","shell.execute_reply.started":"2023-11-20T11:15:51.121766Z"},"trusted":true},"outputs":[],"source":["# Prepare testloaders\n","\n","# RE Fashion-MNIST Testloader |standard|\n","\n","normalize = transforms.Normalize(mean=[0.5], std=[0.5])\n","\n","transform_re = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.RandomErasing(),\n","    normalize\n","])\n","\n","testset_re = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform_re)\n","testloader_re = torch.utils.data.DataLoader(testset_re, batch_size=4, shuffle=False, num_workers=2)\n","\n","\n","# RE Fashion-MNIST Testloader |circular shape|\n","\n","normalize = transforms.Normalize(mean=[0.5], std=[0.5])\n","\n","transform_re_cir = transforms.Compose([\n","    transforms.ToTensor(),\n","    RandomErasingTransform(probability=0.5, value=0, sl=0.02, sh=0.33, shape=\"circle\", blend_edges=False, blend_type=\"random\", blend_factor=0),\n","    normalize\n","])\n","\n","testset_re_cir = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform_re_cir)\n","testloader_re_cir = torch.utils.data.DataLoader(testset_re_cir, batch_size=4, shuffle=False, num_workers=2)\n","\n","\n","# RE Fashion-MNIST Testloader |random shape|\n","\n","normalize = transforms.Normalize(mean=[0.5], std=[0.5])\n","\n","transform_re_rs = transforms.Compose([\n","    transforms.ToTensor(),\n","    RandomErasingTransform(probability=0.5, value=0, sl=0.02, sh=0.33, shape=\"random\", blend_edges=False, blend_type=\"random\", blend_factor=0),\n","    normalize\n","])\n","\n","testset_re_rs = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform_re_rs)\n","testloader_re_rs = torch.utils.data.DataLoader(testset_re_rs, batch_size=4, shuffle=False, num_workers=2)\n","\n","\n","# RE Fashion-MNIST Testloader |blurred edge|\n","\n","normalize = transforms.Normalize(mean=[0.5], std=[0.5])\n","\n","transform_re_be = transforms.Compose([\n","    transforms.ToTensor(),\n","    RandomErasingTransform(probability=0.5, value=0, sl=0.02, sh=0.33, shape=\"rectangle\", blend_edges=True, blend_type=\"random\", blend_factor=0),\n","    normalize\n","])\n","\n","testset_re_be = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform_re_be)\n","testloader_re_be = torch.utils.data.DataLoader(testset_re_be, batch_size=4, shuffle=False, num_workers=2)\n","\n","\n","# RE Fashion-MNIST Testloader |circular shape & blurred edge|\n","\n","normalize = transforms.Normalize(mean=[0.5], std=[0.5])\n","\n","transform_re_cir_be = transforms.Compose([\n","    transforms.ToTensor(),\n","    RandomErasingTransform(probability=0.5, value=0, sl=0.02, sh=0.33, shape=\"circle\", blend_edges=True, blend_type=\"random\", blend_factor=0),\n","    normalize\n","])\n","\n","testset_re_cir_be = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform_re_cir_be)\n","testloader_re_cir_be = torch.utils.data.DataLoader(testset_re_cir_be, batch_size=4, shuffle=False, num_workers=2)\n","\n","\n","# RE Fashion-MNIST Testloader |random shape & blurred edge|\n","\n","normalize = transforms.Normalize(mean=[0.5], std=[0.5])\n","\n","transform_re_rs_be = transforms.Compose([\n","    transforms.ToTensor(),\n","    RandomErasingTransform(probability=0.5, value=0, sl=0.02, sh=0.33, shape=\"circle\", blend_edges=True, blend_type=\"random\", blend_factor=0),\n","    normalize\n","])\n","\n","testset_re_rs_be = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform_re_rs_be)\n","testloader_re_rs_be = torch.utils.data.DataLoader(testset_re_rs_be, batch_size=4, shuffle=False, num_workers=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T11:15:55.255254Z","iopub.status.busy":"2023-11-20T11:15:55.254800Z","iopub.status.idle":"2023-11-20T11:15:55.329472Z","shell.execute_reply":"2023-11-20T11:15:55.328281Z","shell.execute_reply.started":"2023-11-20T11:15:55.255213Z"},"trusted":true},"outputs":[],"source":["# Load and prepare the model for testing\n","\n","model_re_mnist = resnetgray.resnet20gray(option='B')\n","print(model_re_mnist.conv1.weight.shape)\n","\n","# Load the model you want to test\n","\n","# checkpoint_re_mnist_path = '/kaggle/input/baseline-300/baseline_300.th'\n","# checkpoint_re_mnist_path = '/kaggle/input/re-300/re_300.th'\n","# checkpoint_re_mnist_path = '/kaggle/input/re-cs-300/re_cs_300.th'\n","# checkpoint_re_mnist_path = '/kaggle/input/re-rs-300/re_rs_300.th'\n","# checkpoint_re_mnist_path = '/kaggle/input/re-be-300/re_be_300.th'\n","# checkpoint_re_mnist_path = '/kaggle/input/re-cs-be-300/re_cs_be_300.th'\n","checkpoint_re_mnist_path = '/kaggle/input/re-rs-be-300/re_rs_be_300.th'\n","\n","\n","checkpoint_re_mnist = torch.load(checkpoint_re_mnist_path)\n","\n","model_state_dict_re_mnist = checkpoint_re_mnist['state_dict']\n","\n","print(model_state_dict_re_mnist['module.conv1.weight'].shape)\n","\n","new_state_dict_re_mnist = {k.replace('module.', ''): v for k, v in model_state_dict_re_mnist.items()}\n","\n","model_re_mnist.load_state_dict(new_state_dict_re_mnist, strict=False)\n","model_re_mnist = model_re_mnist.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T11:16:21.753033Z","iopub.status.busy":"2023-11-20T11:16:21.752587Z","iopub.status.idle":"2023-11-20T11:16:33.713686Z","shell.execute_reply":"2023-11-20T11:16:33.712337Z","shell.execute_reply.started":"2023-11-20T11:16:21.752991Z"},"trusted":true},"outputs":[],"source":["# Testing model with Baseline testloader. The output is test error rates\n","\n","# [RE ResNet20 | Baseline Fashion-MNIST]\n","\n","model_re_mnist.eval()\n","\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model_re_mnist(images)\n","        _, predicted = outputs.max(1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Test Error [RE ResNet20 | Baseline Fashion-MNIST]: %.2f %%' % (100-(100 * correct / total)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T11:16:37.872554Z","iopub.status.busy":"2023-11-20T11:16:37.872135Z","iopub.status.idle":"2023-11-20T11:17:53.797265Z","shell.execute_reply":"2023-11-20T11:17:53.795867Z","shell.execute_reply.started":"2023-11-20T11:16:37.872512Z"},"trusted":true},"outputs":[],"source":["# Testing model with RE testloaders. The outputs are test error rates\n","\n","# [RE ResNet20 | RE Fashion-MNIST]\n","\n","model_re_mnist.eval()\n","\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader_re:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model_re_mnist(images)\n","        _, predicted = outputs.max(1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Test Error [RE ResNet20 | RE Fashion-MNIST]: %.2f %%' % (100-(100 * correct / total)))\n","\n","# [RE ResNet20 | RE Fashion-MNIST] |circular shape|\n","\n","model_re_mnist.eval()\n","\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader_re_cir:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model_re_mnist(images)\n","        _, predicted = outputs.max(1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Test Error [RE ResNet20 | RE Fashion-MNIST] |circular shape|: %.2f %%' % (100-(100 * correct / total)))\n","\n","# [RE ResNet20 | RE Fashion-MNIST] |random shape|\n","\n","model_re_mnist.eval()\n","\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader_re_rs:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model_re_mnist(images)\n","        _, predicted = outputs.max(1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Test Error [RE ResNet20 | RE Fashion-MNIST] |random shape|: %.2f %%' % (100-(100 * correct / total)))\n","\n","# [RE ResNet20 | RE Fashion-MNIST] |blurred edge|\n","\n","model_re_mnist.eval()\n","\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader_re_be:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model_re_mnist(images)\n","        _, predicted = outputs.max(1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Test Error [RE ResNet20 | RE Fashion-MNIST] |blurred edge|: %.2f %%' % (100-(100 * correct / total)))\n","\n","# [RE ResNet20 | RE Fashion-MNIST] |circular shape & blurred edge|\n","\n","model_re_mnist.eval()\n","\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader_re_cir_be:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model_re_mnist(images)\n","        _, predicted = outputs.max(1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Test Error [RE ResNet20 | RE Fashion-MNIST] |circular shape & blurred edge|: %.2f %%' % (100-(100 * correct / total)))\n","\n","# [RE ResNet20 | RE Fashion-MNIST] |random shape & blurred edge|\n","\n","model_re_mnist.eval()\n","\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader_re_rs_be:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model_re_mnist(images)\n","        _, predicted = outputs.max(1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Test Error [RE ResNet20 | RE Fashion-MNIST] |random shape & blurred edge|: %.2f %%' % (100-(100 * correct / total)))\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":3852716,"sourceId":6677915,"sourceType":"datasetVersion"},{"datasetId":3857266,"sourceId":6688098,"sourceType":"datasetVersion"},{"datasetId":3857268,"sourceId":6688101,"sourceType":"datasetVersion"},{"datasetId":3857357,"sourceId":6688442,"sourceType":"datasetVersion"},{"datasetId":3924037,"sourceId":6823756,"sourceType":"datasetVersion"},{"datasetId":3924254,"sourceId":6824218,"sourceType":"datasetVersion"},{"datasetId":3924461,"sourceId":6824658,"sourceType":"datasetVersion"},{"datasetId":3924743,"sourceId":6825240,"sourceType":"datasetVersion"},{"datasetId":3924973,"sourceId":6825730,"sourceType":"datasetVersion"},{"datasetId":3932318,"sourceId":6840390,"sourceType":"datasetVersion"},{"datasetId":3932531,"sourceId":6840795,"sourceType":"datasetVersion"},{"datasetId":3933055,"sourceId":6841709,"sourceType":"datasetVersion"},{"datasetId":3937315,"sourceId":6849306,"sourceType":"datasetVersion"},{"datasetId":3937571,"sourceId":6849958,"sourceType":"datasetVersion"},{"datasetId":3937856,"sourceId":6850688,"sourceType":"datasetVersion"},{"datasetId":3938331,"sourceId":6851604,"sourceType":"datasetVersion"},{"datasetId":4014664,"sourceId":6985509,"sourceType":"datasetVersion"},{"datasetId":4014668,"sourceId":6985514,"sourceType":"datasetVersion"},{"datasetId":4014671,"sourceId":6985520,"sourceType":"datasetVersion"}],"dockerImageVersionId":30529,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
